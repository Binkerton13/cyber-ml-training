{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Binkerton13/cyber-ml-training/blob/main/scenarios/scenario_03/scenario_03C_ml/notebook.ipynb)\n",
    "\n",
    "# Scenario 03C — AWS CloudTrail API Anomaly Detection (ML‑Heavy)\n",
    "\n",
    "In this scenario, you will build an **anomaly detection model** to identify suspicious AWS CloudTrail API behavior.\n",
    "\n",
    "You will use:\n",
    "- `cloud_api.csv` — raw CloudTrail API events\n",
    "- `cloud_api_features.csv` — engineered features for ML\n",
    "\n",
    "Your goals:\n",
    "1. Explore CloudTrail API behavior.\n",
    "2. Select meaningful ML features.\n",
    "3. Choose an anomaly detection model.\n",
    "4. Train the model.\n",
    "5. Score suspicious API sequences.\n",
    "6. Justify your model choice.\n",
    "7. Save your ML output for grading.\n",
    "\n",
    "This is an **ML‑only** scenario — no SOC triage or MITRE mapping here.\n",
    "Focus on feature engineering, model selection, and anomaly scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure repository path\n",
    "\n",
    "We load logs directly from GitHub using a fixed repo root.\n",
    "Update only the `repo_root` line if the repo moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Instructor when migrating repos):\n",
    "# If this repo moves to a new GitHub org or user, update ONLY this line:\n",
    "repo_root = \"https://raw.githubusercontent.com/Binkerton13/cyber-ml-training/main\"\n",
    "scenario_path = \"scenarios/scenario_03\"\n",
    "log_base = f\"{repo_root}/{scenario_path}/logs/\"\n",
    "log_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load CloudTrail logs and ML feature dataset\n",
    "\n",
    "We load:\n",
    "- `cloud_api.csv` — raw CloudTrail events\n",
    "- `cloud_api_features.csv` — ML‑ready features\n",
    "\n",
    "Your job is to understand the feature space and decide which features matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "api_path = log_base + \"cloud_api.csv\"\n",
    "feat_path = log_base + \"cloud_api_features.csv\"\n",
    "\n",
    "cloud_api_df = pd.read_csv(api_path)\n",
    "features_df = pd.read_csv(feat_path)\n",
    "\n",
    "cloud_api_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize timestamps\n",
    "\n",
    "CloudTrail timestamps are ISO‑8601. Normalize them and extract time‑based features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_api_df['timestamp'] = pd.to_datetime(\n",
    "    cloud_api_df['timestamp'].astype(str).str.replace('Z', '', regex=False),\n",
    "    utc=True,\n",
    "    errors='coerce'\n",
    ")\n",
    "cloud_api_df['hour'] = cloud_api_df['timestamp'].dt.hour\n",
    "cloud_api_df[['timestamp', 'hour']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore CloudTrail API behavior\n",
    "\n",
    "Look for patterns in:\n",
    "- API call frequency\n",
    "- Regions\n",
    "- Resource types\n",
    "- Error codes\n",
    "- Latency\n",
    "\n",
    "Use the starter cells below and extend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: top API actions\n",
    "cloud_api_df['event_name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Explore CloudTrail behavior\n",
    "# Ideas:\n",
    "# - Group by user or role\n",
    "# - Look at unusual regions\n",
    "# - Look at spikes in API activity\n",
    "# - Look at error codes\n",
    "\n",
    "# Write your exploration code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select ML features\n",
    "\n",
    "Use `features_df` to choose which columns to include in your model.\n",
    "\n",
    "Examples:\n",
    "- `api_count_last_1h`\n",
    "- `unique_resources_accessed`\n",
    "- `region_entropy`\n",
    "- `error_rate`\n",
    "- `time_of_day`\n",
    "\n",
    "Your job: choose a subset of features and justify your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select your ML features\n",
    "# Example (replace with your choices):\n",
    "# selected_features = features_df[['api_count_last_1h', 'unique_resources', 'error_rate']]\n",
    "\n",
    "selected_features = features_df.copy()  # Placeholder — modify this\n",
    "selected_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Choose an anomaly detection model\n",
    "\n",
    "Model options:\n",
    "- IsolationForest\n",
    "- LocalOutlierFactor\n",
    "- OneClassSVM\n",
    "\n",
    "Your job:\n",
    "- Choose a model\n",
    "- Initialize it\n",
    "- Justify your choice in the explanation section later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize your anomaly detection model\n",
    "# Example:\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# model = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
    "\n",
    "model = None  # Replace with your model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your model\n",
    "# Example:\n",
    "# model.fit(selected_features)\n",
    "\n",
    "if model is not None:\n",
    "    model.fit(selected_features)\n",
    "else:\n",
    "    raise ValueError(\"You must initialize 'model' before fitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Score suspicious API sequences\n",
    "\n",
    "Use your model to compute anomaly scores.\n",
    "\n",
    "You may:\n",
    "- Score all events\n",
    "- Score a filtered subset\n",
    "- Aggregate scores (mean, min, max)\n",
    "\n",
    "Your job: produce a single `anomaly_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Score suspicious events\n",
    "# Example pattern:\n",
    "# scores = model.decision_function(selected_features)\n",
    "# anomaly_score = float(scores.mean())\n",
    "\n",
    "try:\n",
    "    scores = model.decision_function(selected_features)\n",
    "    anomaly_score = float(scores.mean())\n",
    "except Exception as e:\n",
    "    anomaly_score = 0.0\n",
    "    print(\"Error scoring events:\", e)\n",
    "\n",
    "anomaly_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explain your model choice\n",
    "\n",
    "Write a short explanation of:\n",
    "- Why you chose your model\n",
    "- Why your features make sense\n",
    "- How your model captures anomalous API behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your explanation here\n",
    "\n",
    "explanation = \"\"  # Replace with your explanation\n",
    "explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save ML output\n",
    "\n",
    "This cell saves your ML results for grading.\n",
    "Do not change the keys or filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "os.makedirs(\"student_output\", exist_ok=True)\n",
    "\n",
    "ml_output = {\n",
    "    \"anomaly_score\": anomaly_score,\n",
    "    \"model_used\": type(model).__name__ if model is not None else None,\n",
    "    \"features\": list(selected_features.columns),\n",
    "    \"explanation\": explanation\n",
    "}\n",
    "\n",
    "with open(\"student_output/ml_output.json\", \"w\") as f:\n",
    "    json.dump(ml_output, f, indent=4)\n",
    "\n",
    "print(\"ML output saved to student_output/ml_output.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
